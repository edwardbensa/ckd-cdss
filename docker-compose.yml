services:
  t2v-transformers:
    image: semitechnologies/transformers-inference:sentence-transformers-all-MiniLM-L6-v2
    environment:
      ENABLE_CUDA: '0'
    ports:
      - "9090:8080"

  weaviate:
    image: cr.weaviate.io/semitechnologies/weaviate:1.28.1
    command:
      - --host
      - 0.0.0.0
      - --port
      - '8080'
      - --scheme
      - http
    ports:
      - "8080:8080"   # REST
      - "50051:50051" # gRPC
    volumes:
      - weaviate_data:/var/lib/weaviate
    restart: on-failure
    environment:
      ENABLE_MODULES: 'text2vec-transformers,generative-openai'
      TRANSFORMERS_INFERENCE_API: 'http://t2v-transformers:8080'
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: 'text2vec-transformers'
      CLUSTER_HOSTNAME: 'node1'

  rag-api:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: rag-api
    ports:
      - "8000:8000"
    depends_on:
      - weaviate
    environment:
      - WEAVIATE_HOST=weaviate
      - WEAVIATE_PORT=8080
      - WEAVIATE_GRPC_PORT=50051
      - COHERE_API_KEY=${COHERE_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    restart: on-failure

volumes:
  weaviate_data: