{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80486dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-27 08:35:08.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mLoaded dataset with shape: (399, 26)\u001b[0m\n",
      "\u001b[32m2025-12-27 08:35:08.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLoaded dataset with shape: (565, 20)\u001b[0m\n",
      "\u001b[32m2025-12-27 08:35:08.340\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1mLoaded dataset with shape: (400, 25)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from loguru import logger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.config import TABLES_DIR\n",
    "\n",
    "# Load Hidden CKD\n",
    "df1 = pd.read_csv(TABLES_DIR / \"hiddenckd_01.csv\")\n",
    "logger.info(f\"Loaded dataset with shape: {df1.shape}\")\n",
    "\n",
    "X1 = df1.drop(columns=\"ckd_status\")\n",
    "y1 = df1[\"ckd_status\"]\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(\n",
    "    X1, y1, test_size=0.2, stratify=y1, random_state=42\n",
    ")\n",
    "\n",
    "entry_1 = (\n",
    "    X_test1\n",
    "    .reset_index(drop=True)\n",
    "    .to_dict(orient=\"records\")\n",
    ")\n",
    "\n",
    "df2 = pd.read_csv(TABLES_DIR / \"hiddenckd_02.csv\")\n",
    "logger.info(f\"Loaded dataset with shape: {df2.shape}\")\n",
    "\n",
    "\n",
    "entry_2 = (\n",
    "    df2\n",
    "    .reset_index(drop=True)\n",
    "    .to_dict(orient=\"records\")\n",
    ")\n",
    "\n",
    "# Load UCI ML Repo CKD\n",
    "df3 = pd.read_csv(TABLES_DIR / \"ucickd.csv\")\n",
    "logger.info(f\"Loaded dataset with shape: {df3.shape}\")\n",
    "\n",
    "X2 = df3.drop(columns=\"class\")\n",
    "y2 = df3[\"class\"]\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test = train_test_split(\n",
    "    X2, y2, test_size=0.2, stratify=y2, random_state=42\n",
    ")\n",
    "\n",
    "entry_3 = (\n",
    "    X_test2\n",
    "    .reset_index(drop=True)\n",
    "    .to_dict(orient=\"records\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77a68633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from bson import ObjectId\n",
    "from datetime import date, datetime, time\n",
    "\n",
    "docs = entry_1 + entry_2 + entry_3\n",
    "\n",
    "fields = [\n",
    "    \"email\",\n",
    "    \"postcode\",\n",
    "    \"male\",\n",
    "    \"age\",\n",
    "    \"dob\",\n",
    "    \"eth\",\n",
    "    \"height_cm\",\n",
    "    \"weight_kg\",\n",
    "    \"s_bp\",\n",
    "    \"d_bp\",\n",
    "    \"family_htn\",\n",
    "    \"family_dm\",\n",
    "    \"family_kd\",\n",
    "    \"htn\",\n",
    "    \"dm\",\n",
    "    \"kd\",\n",
    "    \"cvd\",\n",
    "    \"cad\",\n",
    "    \"rbc\",\n",
    "    \"pc\",\n",
    "    \"pcc\",\n",
    "    \"ba\",\n",
    "    \"bgr\",\n",
    "    \"bu\",\n",
    "    \"sc\",\n",
    "    \"su\",\n",
    "    \"al\",\n",
    "    \"sg\",\n",
    "    \"sod\",\n",
    "    \"pot\",\n",
    "    \"hemo\",\n",
    "    \"pcv\",\n",
    "    \"wbcc\",\n",
    "    \"rbcc\",\n",
    "    \"appet_poor\",\n",
    "    \"pe\",\n",
    "    \"ane\",\n",
    "    \"screening_acr\",\n",
    "    \"device\",\n",
    "    \"acr\",\n",
    "    \"egfr\",\n",
    "    \"acr_stage\",\n",
    "    \"egfr_stage\",\n",
    "]\n",
    "\n",
    "filtered_docs = []\n",
    "\n",
    "for idx, d in enumerate(docs):\n",
    "    new_doc = {}\n",
    "    for i in fields:\n",
    "        if i in d:\n",
    "            new_doc[\"_id\"] = idx+1\n",
    "            new_doc[\"patient_id\"] = idx+1\n",
    "            new_doc[i] = d[i]\n",
    "        else:\n",
    "            pass\n",
    "    filtered_docs.append(new_doc)\n",
    "\n",
    "with open(\"ckd_docs.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(filtered_docs, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7801f4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client[\"ckd_cdss\"]\n",
    "collection = db[\"patients\"]\n",
    "\n",
    "for doc in filtered_docs:\n",
    "    if isinstance(doc.get(\"dob\"), str):\n",
    "        doc[\"dob\"] = datetime.fromisoformat(doc[\"dob\"])\n",
    "\n",
    "for d in filtered_docs:\n",
    "    d[\"_id\"] = ObjectId()\n",
    "\n",
    "collection.drop()\n",
    "result = collection.insert_many(filtered_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "711395f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "missing_patient_id = sum(\"patient_id\" not in d for d in filtered_docs)\n",
    "print(missing_patient_id)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
